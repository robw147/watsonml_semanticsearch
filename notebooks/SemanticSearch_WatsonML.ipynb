{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
    "# Click on the toolbar icon with the Insert Project token option (three dots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Deployment of Functions to Watson ML\n",
    "This notebook contains steps and code to demonstrate how to deploy Python Functions to the Watson Machine Learning service. It facilitates [ibm-watson-machine-learning](https://pypi.python.org/pypi/ibm-watson-machine-learning) library available in PyPI repository. It introduces commands for creating, updating & deleting spaces, deploying getting list and detailed information about them. It then publishes and deploys two Python functions. Firstly a very simple Python Function then a function that builds and deploys an NLP model as a Python function in Watson ML.\n",
    "\n",
    "This notebook uses Python 3.10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "\n",
    "1.  [Set up the environment](#setup)\n",
    "2.  [Create new space](#create_space)\n",
    "3.  [List all existing spaces](#list_space)\n",
    "4.  [Get details about space](#get_space)\n",
    "5.  [Set default space](#set_space)\n",
    "6.  [Deploy Python Function](#deploy_function)\n",
    "7.  [Delete existing space](#delete_space)\n",
    "8.  [Summary and next steps](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to WML\n",
    "\n",
    "Authenticate the Watson Machine Learning service on IBM Cloud. You need to provide platform `api_key` and instance `location`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Your `Cloud API key` can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below. You can also get a service specific url by going to the [**Endpoint URLs** section of the Watson Machine Learning docs](https://cloud.ibm.com/apidocs/machine-learning).  You can check your instance location in your  <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance details.\n",
    "\n",
    "You can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.\n",
    "\n",
    "**Action**: Enter your `api_key` and `location` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'PASTE THE CLOUD API KEY'\n",
    "location = 'PASTE LOCATION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": api_key,\n",
    "    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import the `ibm-watson-machine-learning` package\n",
    "**Note:** `ibm-watson-machine-learning` documentation can be found <a href=\"http://ibm-wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "!pip install -U ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"create_space\"></a>\n",
    "## 2. Create new space\n",
    "\n",
    "There are two ways to create a Watson Mchine Learning Deployment Space. In this notebook, we will cover option **2. Programmatically using Python**\n",
    "\n",
    "**1. Through the menu system**\n",
    "you need to create a space that will be used for your work. If you do not have space already created, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create one.\n",
    "\n",
    "- Click New Deployment Space\n",
    "- Create an empty space\n",
    "- Select Cloud Object Storage\n",
    "- Select Watson Machine Learning instance and press Create\n",
    "- Copy `space_id` and paste it below\n",
    "\n",
    "**2. Programmatically using Python**\n",
    "\n",
    "To do this we use the `ibm_watson_machine_learning` SDK to prepare the space for your work. The steps to perform it are described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following information is required\n",
    "\n",
    "1. The `space_name` this can be any name you would like to give the deployment spaces. This is where all of your assets will be moved to from the Watson Studio project for the deployment.\n",
    "\n",
    "2. In addition you will need to define space metadata. \n",
    "\n",
    "i. You will need Watson Machine Learning instance `wml_service_name` and the `wml_crn`\n",
    "You can get your WML instance `name` and `crn` by following the instructions from [Setup](#setup). \n",
    "\n",
    "ii. The `cos_resource_crn` is the Cloud Object Storage `crn`. \n",
    "You can get Cloud Object Storage `crn` by following steps:\n",
    "\n",
    "- Go to [IBM Cloud website](https://cloud.ibm.com/)\n",
    "- Choose storage from your Dashboard\n",
    "- Select your cloud object storage\n",
    "- Choose Service Credentials from the Menu on the left\n",
    "- Create new credentials by clicking New Credentials or open existing credentials with Writer priviledges\n",
    "- Copy `resource_instance_id` field and paste it below as `cos_resource_crn`\n",
    "\n",
    "**Tip:** If you already have a space and you want to create a new one, you can get metadata required for space creation from your existing space details by running `client.spaces.get_details(your_space_id)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next you can create space by following cell execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_name = 'PASTE THE WATSON ML DEPLOYMENT SPACE NAME'\n",
    "wml_service_name = 'PASTE THE WATSON ML SERVICE NAME'\n",
    "wml_crn = 'PASTE THE WATSON ML CRN'\n",
    "cos_resource_crn = 'PASTE THE COS RESOURCE CRN'\n",
    "use_existing_space=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following code checks if a deployment space with the `space_name` specified above exists. If it does, the existing deployment space will be used, otherwise a new deplyment space will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_uid=\"\"\n",
    "for space in client.spaces.get_details()['resources']:\n",
    "\n",
    "    if space['entity']['name'] ==space_name:\n",
    "        print(\"Deployment space with name\",space_name,\"already exists . .\")\n",
    "        space_uid=space['metadata']['id']\n",
    "        client.set.default_space(space_uid)\n",
    "        if(use_existing_space==False):\n",
    "\n",
    "            for deployment in client.deployments.get_details()['resources']:\n",
    "                print(\"Deleting deployment\",deployment['entity']['name'], \"in the space\",)\n",
    "                deployment_id=deployment['metadata']['id']\n",
    "                client.deployments.delete(deployment_id)\n",
    "            print(\"Deleting Space \",space_name,)\n",
    "            client.spaces.delete(space_uid)\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            print(\"Using the existing space\")\n",
    "            \n",
    "            \n",
    "if (space_uid==\"\" or use_existing_space==False):\n",
    "    print(\"\\nCreating a new deployment space -\",space_name)\n",
    "    # create the space and set it as default\n",
    "    space_metadata = {\n",
    "        'name': space_name,\n",
    "        'description': 'This is a test deployment space',\n",
    "        'storage': {\n",
    "            'type': 'bmcos_object_storage',\n",
    "            'resource_crn': cos_resource_crn\n",
    "        },\n",
    "        'compute': {\n",
    "            'name': wml_service_name,\n",
    "            'crn': wml_crn\n",
    "        }\n",
    "    }\n",
    "    stored_space_details = client.spaces.store(space_metadata)\n",
    "\n",
    "    space_uid = stored_space_details['metadata']['id']\n",
    "\n",
    "    client.set.default_space(space_uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Details of the deployment spaces uid\n",
    "print(space_uid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Tip** In order to check if the space creation is completed succesfully change next cell format to code and execute it. It should return 'active'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "client.spaces.get_details(space_uid)['entity']['status']['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Action**: If you didn't create new space in this notebook by `ibm_watson_machine_learning`, please assign space uid below and change cell format to `code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "space_uid = '75dd5a94-4700-4934-a126-bb64a4622682'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"list_space\"></a>\n",
    "## 3. List all existing spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use `list` method to print all existing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client.spaces.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_space\"></a>\n",
    "## 4. Get details about space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `get_details` method to print details about given space. You need to provide `space_id` of desired space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.spaces.get_details(space_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"set_space\"></a>\n",
    "## 5. Set default space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To be able to interact with all resources available in Watson Machine Learning, you need to set **space** which you will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy_function\"></a>\n",
    "## 6. Deploy Python Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Simple Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Create the Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wml_python_function\n",
    "def my_deployable_function():\n",
    "    def score( payload ):\n",
    "        a=payload['input_data'][0]['values'][0]\n",
    "        b=payload['input_data'][0]['values'][1]\n",
    "        # append that to the master result \n",
    "        c=a+b\n",
    "        c = str(c)\n",
    "        # create an empty list to store all results, if multiple users are passed as input \n",
    "        all_outputs = []\n",
    "        all_outputs.append(list(c))\n",
    "        # format everything into a dictionary format WML can interact with \n",
    "        score_output = {'predictions': [{'values': c}]}\n",
    "        return score_output\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function locally\n",
    "func_result = my_deployable_function()({\"input_data\": [{\"values\": [4, 5]}]})\n",
    "print(func_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Deploy and Test the Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up software specification for the deployable function\n",
    "\n",
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.2-py3.10\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the deployable function in your Watson Machine Learning repository\n",
    "\n",
    "meta_data = {\n",
    "    client.repository.FunctionMetaNames.NAME: 'My Test Python Deployment Function',\n",
    "    client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "}\n",
    "\n",
    "function_details = client.repository.store_function(meta_props=meta_data, function=my_deployable_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get published function ID\n",
    "\n",
    "function_uid = client.repository.get_function_uid(function_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the stored function\n",
    "\n",
    "metadata = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: 'My Test Deployment',\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "\n",
    "function_deployment_details = client.deployments.create(function_uid, meta_props=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. SemanticSearch Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Load Data, Model and Create Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FAQ Question Answer Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = json.load(project.get_file('data_for_train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "for i in range(len(qa)):\n",
    "    questions.append(qa[i]['Question'])\n",
    "    answers.append(qa[i]['Answer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame({'questions': questions, 'answers': answers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might be the best\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# alternative models\n",
    "# model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "# model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "# model = SentenceTransformer('clips/mfaq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = testing['questions'].astype(str).tolist()\n",
    "corpus_embed = model.encode(q_list, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = testing['questions'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Create the Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faq_answer(question, corpus, q_list, nr, top_k=10, score=0.5):\n",
    "    qe = model.encode(question)\n",
    "    print(qe)\n",
    "    print(type(qe))\n",
    "    print(corpus)\n",
    "    print(top_k)\n",
    "    hits = util.semantic_search(qe, corpus, top_k)\n",
    "    print(hits)\n",
    "    output = []\n",
    "    for hit in hits[0]:\n",
    "        d = {}\n",
    "        if hit['score'] > score:\n",
    "            d['question'] = q_list[hit['corpus_id']]\n",
    "            d['score'] = hit['score']\n",
    "            d['answer'] = nr.loc[nr['questions'] == q_list[hit['corpus_id']]]['answers'].to_string(index=False)\n",
    "        output.append(d)\n",
    "    print('scoreOutputType',type(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I visited Sweden this week, it was very cold\"\n",
    "# question = \"I watched TV last night, love watching the news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question (type:str) is the payload, i.e. the user's input\n",
    "# corpus_embed (type: torch.Tensor) is the tensor model\n",
    "# testing (type: dataFrame) includes questions and answers\n",
    "# q_list (type: list) is the list of questions (based off the questions in the testing dataframe)\n",
    "# top_k (type:int) top N scores to return\n",
    "# score (type:int) return scores over this threshold value\n",
    "# output (type: list)\n",
    "output = faq_answer(question, corpus_embed, q_list, testing, top_k=10, score=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Deploy and Test the Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in the local directly \n",
    "# This is not saved to the project directory, but the local memory of the Jupyter pod that is ephemeral\n",
    "# We only need access to this momentarily to promote the assets to the deployment space \n",
    "\n",
    "with open(r\"corpus_embed.p\", \"wb\") as output_file:\n",
    "    pickle.dump(corpus_embed, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_csv('testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the WML client API to move (promote) these assets to the deployment space \n",
    "asset_details_model = client.data_assets.create('corpus_embed.p', file_path='corpus_embed.p')\n",
    "testing = client.data_assets.create('testing.csv', file_path='testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IDs of the promoted assets \n",
    "model_id = asset_details_model['metadata']['guid']\n",
    "testing_id = testing['metadata']['guid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model id:',model_id,'Testing id:',testing_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format everything to reside in the assets_dict dictionary object \n",
    "assets_dict = {'model_id' : model_id, 'testing_id': testing_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ai_parms dictionary that contains the WML credentials, space ID and the assets_dict dictionary\n",
    "# This helps access all the information together later on\n",
    "\n",
    "ai_parms = {\"wml_credentials\": wml_credentials, \"space_uid\": space_uid, 'assets' : assets_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a definition of the deployment function\n",
    "def faq_answer_wml(parms=ai_parms):\n",
    "    import os\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    try:\n",
    "        import subprocess\n",
    "        subprocess.check_output(\"pip install sentence-transformers --user\", stderr=subprocess.STDOUT, shell=True)\n",
    "        subprocess.check_output(\"pip install spacy --user\", stderr=subprocess.STDOUT, shell=True)\n",
    "        subprocess.check_output(\"python -m spacy download en_core_web_md --user\", stderr=subprocess.STDOUT, shell=True)\n",
    "        subprocess.check_output(\"pip install autocorrect --user\", stderr=subprocess.STDOUT, shell=True)\n",
    "        \n",
    "        # import all the necessary packages\n",
    "        import pickle\n",
    "        from ibm_watson_machine_learning import APIClient\n",
    "        from autocorrect import Speller, word_regexes\n",
    "        import spacy\n",
    "        from tqdm.notebook import tqdm\n",
    "        from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "        import pickle\n",
    "        import re\n",
    "        import json\n",
    "        import ast\n",
    "        import pandas as pd\n",
    "        from autocorrect import Speller, word_regexes\n",
    "        import spacy\n",
    "        from tqdm.notebook import tqdm\n",
    "        from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "        # instantiate the WML client \n",
    "        client = APIClient(parms[\"wml_credentials\"])\n",
    "        client.set.default_space(parms[\"space_uid\"])\n",
    "            \n",
    "        # get the path to the model and the necessary files locally \n",
    "        model_path = client.data_assets.download(parms['assets']['model_id'], 'corpus_embed.p')\n",
    "        testing_path =  client.data_assets.download(parms['assets']['testing_id'], 'testing.csv')\n",
    "\n",
    "        # read the files locally\n",
    "        testing = pd.read_csv('testing.csv')\n",
    "\n",
    "        # Initiate the model\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "        q_list = testing['questions'].astype(str).tolist()         \n",
    "\n",
    "        # load the model locally \n",
    "        with open(str(model_path), \"rb\") as input_file:\n",
    "            corpus_embed = pickle.load(input_file)\n",
    "\n",
    "        def get_faq_answer(question, corpus, q_list, nr, top_k=10, score=0.5):\n",
    "            qe = model.encode(question)\n",
    "            hits = util.semantic_search(qe, corpus, top_k)\n",
    "            output = []\n",
    "            for hit in hits[0]:\n",
    "                d = {}\n",
    "                if hit['score'] > score:\n",
    "                    d['question'] = q_list[hit['corpus_id']]\n",
    "                    d['score'] = hit['score']\n",
    "                    d['answer'] = nr.loc[nr['questions'] == q_list[hit['corpus_id']]]['answers'].to_string(index=False)\n",
    "                output.append(d)\n",
    "            return output\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:        \n",
    "        install_err = \"subprocess.CalledProcessError:\\n\\n\" + \"cmd:\\n\" + e.cmd + \"\\n\\noutput:\\n\" + e.output.decode()\n",
    "        raise Exception(\"Installing failed:\\n\" + install_err)\n",
    "    \n",
    "\n",
    "    \n",
    "    # define the score function \n",
    "    def score(function_payload):\n",
    "            \n",
    "        try:\n",
    "            \n",
    "            # iterate over each question in the payload \n",
    "            all_output = []\n",
    "            \n",
    "            for input_values in function_payload[\"input_data\"][0][\"values\"]:\n",
    "                question = str(input_values[0])\n",
    "                output = get_faq_answer(question, corpus_embed, q_list, testing, top_k=10, score=0.0)\n",
    "                all_output.append(output)\n",
    "            \n",
    "            score_response = {\n",
    "                \"predictions\": [\n",
    "                    {\n",
    "                        \"fields\": [\"question\"],\n",
    "                        \"values\": [all_output]\n",
    "                    }\n",
    "                ]\n",
    "            } \n",
    "            \n",
    "            return score_response\n",
    "    \n",
    "\n",
    "        # if there is an exception \n",
    "        except Exception as e:\n",
    "\n",
    "            # return the error \n",
    "            score_response = {\n",
    "                \"predictions\": [\n",
    "                    {\n",
    "                        \"fields\": [\"error\"],\n",
    "                        \"values\": [\n",
    "                            [ e.__repr__() ]\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            } \n",
    "            return score_response\n",
    "\n",
    "    # return the score function \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function locally\n",
    "\n",
    "job_payload = {\n",
    "    \"input_data\": [\n",
    "        {\n",
    "            \"fields\": [\"question\"],\n",
    "            \"values\": [\n",
    "                [\"I went to London for a business meeting?\"],\n",
    "                [\"I watched TV last night, love watching the news\"]\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "output = faq_answer_wml()(job_payload)\n",
    "# faq_answer_wml()({\"input_data\": [{\"values\": [\"I watched TV last night, love watching the news\"]}]})\n",
    "#faq_answer_wml()({\"input_data\": [{\"values\": ['I drive a fast car']}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"predictions\"][0][\"values\"][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy_function\"></a>\n",
    "## 8. Deploy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up software specification for the deployable function\n",
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.2-py3.10\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the deployable function in your Watson Machine Learning repository\n",
    "meta_data = {\n",
    "    client.repository.FunctionMetaNames.NAME: 'NLP FAQ Model',\n",
    "    client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "}\n",
    "\n",
    "function_details = client.repository.store_function(meta_props=meta_data, function=faq_answer_wml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get published function ID\n",
    "function_uid = client.repository.get_function_uid(function_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the stored function\n",
    "\n",
    "metadata = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: 'NLP FAQ Model',\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "\n",
    "function_deployment_details = client.deployments.create(function_uid, meta_props=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 8. Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You successfully completed this notebook! You learned how to use ibm-watson-machine-learning client for Watson Machine Learning instance space management and clean up. Check out our _[Online Documentation](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/welcome-main.html?context=analytics?pos=2)_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_id = function_deployment_details[\"metadata\"][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_payload = {\n",
    "    \"input_data\": [\n",
    "        {\n",
    "            \"fields\": [\"question\"],\n",
    "            \"values\": [\n",
    "                [\"I went to London for a business meeting?\"],\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(job_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details = client.deployments.score(deployment_id, job_payload)\n",
    "print(job_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details[\"predictions\"][0][\"values\"][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
